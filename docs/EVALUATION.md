# Оценка и сравнение

Этот документ описывает, как вычислять метрики качества, строить матрицы ошибок, агрегировать результаты по SNR и сравнивать ML и DL модели.

Исходники:
- `evaluate_compare.py` — сводная оценка и графики Accuracy/F1 vs SNR, матрицы ошибок.
- `error_analysis.py` — дополнительная диагностика ошибок и важности признаков.

---

## 1. Метрики

- Accuracy (доля верных предсказаний).
- F1‑macro (по классам отдельно → усреднение).
- F1‑micro (по всем примерам суммарно).
- Матрица ошибок (confusion matrix) с нормировкой по строкам.

---

## 2. Агрегация по SNR

- Биннинг по SNR (например, шаг 2–6 дБ) для оценки устойчивости.
- Вывод графиков Accuracy/F1 vs SNR для моделей ML и DL.

---

## 3. Процедура запуска

```bash
python evaluate_compare.py --train data/train_v1.npz --val data/val_v1.npz --test data/test_v1.npz
```

- Скрипт загрузит артефакты обучения, рассчитает метрики на тесте и сохранит графики/матрицы в `reports/`.

---

## 4. Интерпретация

- Смотрите, в каких классах путаница максимальна — это кандидаты на улучшение генерации или аугментаций.
- Анализируйте деградацию по SNR — полезно для выбора рабочих диапазонов.
- Сравнивайте ML на признаках vs DL на raw IQ/спектрограммах.

---

## 5. Полезные ссылки

- Теория метрик и матриц ошибок: `THEORY_BEGINNER.md` (§26)
- Быстрый BER демо‑модема: `img/ber_curves.png` (генерируется `quick_modem_demo.py`)
